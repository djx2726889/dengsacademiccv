<!DOCTYPE HTML>
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <title>Jiaxin Deng</title>
  
  <meta name="author" content="Jiaxin Deng">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
  <link rel="stylesheet" type="text/css" href="stylesheet.css">
	<link rel="icon" href="data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22>üåê</text></svg>">
</head>

<body>
  <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr style="padding:0px">
      <td style="padding:0px">
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr style="padding:0px">
            <td style="padding:2.5%;width:63%;vertical-align:middle">
              <p style="text-align:center">
                <name>Jiaxin Deng</name>
              </p>
              <p>I am a master student at <a href="http://www.ia.cas.cn/">Institution of Automation</a> in Beijing, where I work on video mutli-modal understanding and time series mining.
              </p>
              <p>
		I did my undergraduate degree at <a href="https://www.uestc.edu.cn/">UESTC</a> and I am doing my Master's Degree at <a href="http://www.ia.cas.cn/">Institution of Automation</a>, where I am advised by <a href="https://people.ucas.ac.cn/~gfmeng">Gaofeng Meng</a>.
              </p>
              <p style="text-align:center">
                <a href="mailto:2532088315@qq.com">Email</a> &nbsp/&nbsp
                <a href="data/JonBarron-CV.pdf">CV</a> &nbsp/&nbsp
                <a href="data/JonBarron-bio.txt">Bio</a> &nbsp/&nbsp
                <a href="https://twitter.com/orpheusann">Twitter</a> &nbsp/&nbsp
                <a href="https://github.com/djx2726889/">Github</a>
              </p>
            </td>
            <td style="padding:2.5%;width:40%;max-width:40%">
              <a href="images/dengjiaxinme2.jpg"><img style="width:100%;max-width:100%" alt="profile photo" src="images/dengjiaxinme2.jpg" class="hoverZoomLink"></a>
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Research</heading>
              <p>
		I'm interested in multi-modal video understanding, continual learning, and time series mining. Much of my research is about mutli-modal learning (visual, text, speech, etc) from videos. Representative papers are <span class="highlight">highlighted</span>.
              </p>
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
				
	  
	<tr onmouseout="losstest_stop()" onmouseover="losstest_start()" bgcolor="#ffffd0">
	  <td style="padding:20px;width:25%;vertical-align:middle">
	    <div class="one" style="position: relative;">
	      <div class="two" id='losstest_image'><img src='images/icmr_after.png' width="160"></div>
	      <img src='images/icmr_before.png' width="160" style="position: absolute; top: 0; left: 0;">
	    </div>
	    <script type="text/javascript">
	      function losstest_start() {
		document.getElementById('losstest_image').style.opacity = "1";
	      }

	      function losstest_stop() {
		document.getElementById('losstest_image').style.opacity = "0";
	      }
	      loss_stop()
	    </script>
	  </td>
	  <td style="padding:20px;width:75%;vertical-align:middle">
	    <a href="https://arxiv.org/abs/2211.10624">
	      <papertitle>A Unified Model for Video Understanding and Knowledge Embedding with Heterogeneous Knowledge Graph Dataset</papertitle>
	    </a>
	    <br>
	    <strong>Jiaxin Deng</strong>
	    <br>
	    <em>ICMR</em>, 2023 &nbsp <font color="red"><strong>(Oral Presentation, Best Pa	per Award Candidate)</strong></font>
	    <br>
	    <a href="https://arxiv.org/abs/2211.10624">arxiv</a> /
	    <a href="https://www.dropbox.com/s/qsou4k286fhjnkw/icmr_jiaxindeng.mp4?dl=0">video</a> 
	    <p></p>
	    <p>we propose a heterogeneous dataset that contains the multi-modal video entity and fruitful common sense relations. This dataset also provides multiple novel video inference tasks like the Video-Relation-Tag (VRT) and Video-Relation-Video (VRV) tasks. Furthermore, based on this dataset, we propose an end-to-end model that jointly optimizes the video understanding objective with knowledge graph embedding, which can not only better inject factual knowledge into video understanding but also generate effective multi-modal entity embedding for KG.</p>
	  </td>
	</tr>

          <tr onmouseout="loss_stop()" onmouseover="loss_start()" bgcolor="#ffffd0">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='loss_image'><img src='images/icmr_all.png' width="160"></div>
                <img src='images/icmr_all.png' width="160">
              </div>
              <script type="text/javascript">
                function loss_start() {
                  document.getElementById('loss_image').style.opacity = "1";
                }

                function loss_stop() {
                  document.getElementById('loss_image').style.opacity = "0";
                }
                loss_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://arxiv.org/abs/2211.10624">
                <papertitle>A Unified Model for Video Understanding and Knowledge Embedding with Heterogeneous Knowledge Graph Dataset</papertitle>
              </a>
              <br>
              <strong>Jiaxin Deng</strong>
              <br>
              <em>ICMR</em>, 2023 &nbsp <font color="red"><strong>(Oral Presentation, Best Paper Award Candidate)</strong></font>
              <br>
              <a href="https://arxiv.org/abs/2211.10624">arxiv</a> /
              <a href="https://www.dropbox.com/s/qsou4k286fhjnkw/icmr_jiaxindeng.mp4?dl=0">video</a> 
              <p></p>
              <p>we propose a heterogeneous dataset that contains the multi-modal video entity and fruitful common sense relations. This dataset also provides multiple novel video inference tasks like the Video-Relation-Tag (VRT) and Video-Relation-Video (VRV) tasks. Furthermore, based on this dataset, we propose an end-to-end model that jointly optimizes the video understanding objective with knowledge graph embedding, which can not only better inject factual knowledge into video understanding but also generate effective multi-modal entity embedding for KG.</p>
            </td>
          </tr>





        </tbody></table>

				
        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20"><tbody>
          <tr>
            <td>
              <heading>Misc</heading>
            </td>
          </tr>
        </tbody></table>
        <table width="100%" align="center" border="0" cellpadding="20"><tbody>
					
          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle"><img src="images/cvf.jpg"></td>
            <td width="75%" valign="center">
              <a href="https://cvpr2022.thecvf.com/area-chairs">Area Chair, CVPR 2022</a>
              <br>
              <a href="http://cvpr2021.thecvf.com/area-chairs">Area Chair & Longuet-Higgins Award Committee Member, CVPR 2021</a>
              <br>
              <a href="http://cvpr2019.thecvf.com/area_chairs">Area Chair, CVPR 2019</a>
              <br>
              <a href="http://cvpr2018.thecvf.com/organizers/area_chairs">Area Chair, CVPR 2018</a>
            </td>
          </tr>
          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/cs188.jpg" alt="cs188">
            </td>
            <td width="75%" valign="center">
              <a href="http://inst.eecs.berkeley.edu/~cs188/sp11/announcements.html">Graduate Student Instructor, CS188 Spring 2011</a>
              <br>
              <a href="http://inst.eecs.berkeley.edu/~cs188/fa10/announcements.html">Graduate Student Instructor, CS188 Fall 2010</a>
              <br>
              <a href="http://aima.cs.berkeley.edu/">Figures, "Artificial Intelligence: A Modern Approach", 3rd Edition</a>
            </td>
          </tr>
					

          <tr>
            <td align="center" style="padding:20px;width:25%;vertical-align:middle">
							<heading>Basically <br> Blog Posts</heading>
            </td>
            <td width="75%" valign="middle">
              <a href="https://arxiv.org/abs/2112.11687">Squareplus: A Softplus-Like Algebraic Rectifier</a>
              <br>
              <a href="https://arxiv.org/abs/2010.09714">A Convenient Generalization of Schlick's Bias and Gain Functions</a>
              <br>
              <a href="https://arxiv.org/abs/1704.07483">Continuously Differentiable Exponential Linear Units</a>
            </td>
          </tr>
					
					
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <td style="padding:0px">
              <br>
              <p style="text-align:right;font-size:small;">
                Feel free to steal this website's <a href="https://github.com/jonbarron/jonbarron_website">source code</a>. <strong>Do not</strong> scrape the HTML from this page itself, as it includes analytics tags that you do not want on your own website &mdash; use the github code instead. Also, consider using <a href="https://leonidk.com/">Leonid Keselman</a>'s <a href="https://github.com/leonidk/new_website">Jekyll fork</a> of this page.
              </p>
            </td>
          </tr>
        </tbody></table>
      </td>
    </tr>
  </table>
</body>

</html>
